import requests
from bs4 import BeautifulSoup
import os
import re

# Define the search term and number of images to download
search_term = 'stuffed animals'
num_images = 10

# Define the URL for the Google Images search
url = f'https://www.google.com/search?q={search_term}&source=lnms&tbm=isch'
url = 'https://www.google.com/search?q=stuffed+animals&tbm=isch&source=hp&biw=743&bih=669&ei=r_NSZJzrIceZptQPkZaYuA8&iflsig=AOEireoAAAAAZFMBv5yzKDR5PqwZZOpj6Npp2wbekJKg&ved=0ahUKEwjc_uX2q9r-AhXHjIkEHRELBvcQ4dUDCAc&uact=5&oq=stuffed+animals&gs_lcp=CgNpbWcQAzIICAAQgAQQsQMyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6BAgAEAM6CAgAELEDEIMBUABYgwxg8wxoAHAAeACAAUuIAcUHkgECMTWYAQCgAQGqAQtnd3Mtd2l6LWltZw&sclient=img'
# Set the user-agent to avoid being blocked by Google
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}

# Make a GET request to the search URL
response = requests.get(url, headers=headers)


# Use BeautifulSoup to parse the HTML response
soup = BeautifulSoup(response.content, 'html.parser')

# Find all the image tags in the parsed HTML
img_tags = soup.find_all('img', {'src' : re.compile(r'(jpe?g)|(png)$')})

# Create a directory to save the images
if not os.path.exists(search_term):
    os.makedirs(search_term)

# Download the images to the directory
for i, img_tag in enumerate(img_tags[:num_images]):
    try:
        # Extract the URL of the image
        img_url = img_tag['src']
        
        # Make a GET request to the image URL
        img_response = requests.get(img_url)

        # Save the image to a file
        with open(f'{search_term}/{search_term}_{i+1}.jpg', 'wb') as f:
            f.write(img_response.content)
            
    except:
        pass